{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from pandas import read_csv\n",
    "from tqdm import tqdm  # For the loading bar effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIRECTORY = \"./trainingData/\"  # Remember to add a \"/\" at the end\n",
    "TESTING_DIRECTORY = \"./testData/\"  # Remember to add a \"/\" at the end\n",
    "OUTPUT_DIRECTORY = \"./output/\"  # Remember to add a \"/\" at the end\n",
    "\n",
    "NO_ENTRIES_TAKING_AVG = 10  # No entries to consider when taking average\n",
    "FORECAST_STEP = 5  # No entries to predict ahead of time\n",
    "\n",
    "NO_EPOCHS = 100\n",
    "VAL_SPLIT = 0.2\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "MODEL_PLOT_NAME = \"Forecaster\"  # A \".png\" will be appended to this at the end\n",
    "MODEL_OUTPUT_NAME = f\"Forecaster_FC{FORECAST_STEP}\"  # Name of the model's file (without .h5)\n",
    "MODEL_CHECKPOINT_NAME = f\"ForecasterCP_FC{FORECAST_STEP}\"  # Name of the model's checkpoint file (without .hdf5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Obtaining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting stock and sentiment files: 100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONS\n",
    "def get_data_values(stock_directory, root_directory):\n",
    "    max_stock_price = -float(\"inf\")\n",
    "    min_stock_price = float(\"inf\")\n",
    "    \n",
    "    stock_symbol = stock_directory\n",
    "    stock_dir = root_directory + stock_symbol + \"/\"\n",
    "\n",
    "    # Load stock prices from the CSV file\n",
    "    stock_data = read_csv(stock_dir + stock_symbol + \".csv\", header=0, squeeze=True)\n",
    "\n",
    "    # Drop the columns \"High\", \"Low\", \"Open\", \"Adj Close\" and \"Volume\", i.e. only leave the \"Date\" and \"Close\" column.\n",
    "    stock_data = stock_data.drop(stock_data.columns[list(range(1, 4)) + list(range(5, 7))], axis=1)\n",
    "\n",
    "    # Load sentiment data\n",
    "    sentiment_data = read_csv(stock_dir + stock_symbol + \"_Sentiments.csv\", header=0, squeeze=True)\n",
    "\n",
    "    # Get common dates\n",
    "    common_dates = list(np.intersect1d(sentiment_data[\"Date\"], stock_data[\"Date\"]))\n",
    "    combined_dataframe = pd.DataFrame(columns=[\"Close\", \"Sentiment\"])\n",
    "\n",
    "    # Get common data and save\n",
    "    common_dates_index = 0\n",
    "\n",
    "    temp_stock_values = []\n",
    "    temp_saved_prices_indexes = []\n",
    "\n",
    "    for index in range(stock_data.shape[0]):\n",
    "        temp_stock_values.append(stock_data.iloc[index][\"Close\"])\n",
    "\n",
    "        # Save values with date in the commonDates array to the combinedDataframe\n",
    "        if stock_data.iloc[index][\"Date\"] in common_dates:\n",
    "            # Get the stock value\n",
    "            stock_val = stock_data.iloc[index][\"Close\"]  # Close value\n",
    "\n",
    "            # Save this stock value's index to savedPricesIndexes\n",
    "            temp_saved_prices_indexes.append(index)\n",
    "\n",
    "            # Check and compare with maximum / minimum stock values\n",
    "            if stock_val < min_stock_price:\n",
    "                min_stock_price = stock_val\n",
    "\n",
    "            if stock_val > max_stock_price:\n",
    "                max_stock_price = stock_val\n",
    "\n",
    "            # Assign values to the combined dataframe\n",
    "            combined_dataframe.at[common_dates_index, \"Close\"] = stock_val\n",
    "            combined_dataframe.at[common_dates_index, \"Sentiment\"] = sentiment_data.iloc[common_dates_index][\"Sentiment\"]  # Sentiment value\n",
    "\n",
    "            # Increment commonDatesIndex by 1\n",
    "            common_dates_index += 1\n",
    "\n",
    "    return combined_dataframe, temp_stock_values, temp_saved_prices_indexes, max_stock_price, min_stock_price\n",
    "\n",
    "# Get all training data\n",
    "trainingDirs = next(os.walk(TRAINING_DIRECTORY))[1]  # All the subdirectories\n",
    "\n",
    "trainingDFs = []\n",
    "stockValues = []\n",
    "savedPricesIndexes = []\n",
    "\n",
    "maxStockPrice = -float(\"inf\")\n",
    "minStockPrice = float(\"inf\")\n",
    "\n",
    "for directory in tqdm(trainingDirs, desc=\"Getting stock and sentiment files\"):\n",
    "    combinedDataframe, tempStockValues, tempSavedPricesIndexes, maxi, mini = get_data_values(directory, TRAINING_DIRECTORY)\n",
    "    \n",
    "    trainingDFs.append(combinedDataframe)\n",
    "    stockValues.append(tempStockValues)\n",
    "    savedPricesIndexes.append(tempSavedPricesIndexes)\n",
    "\n",
    "    maxStockPrice = maxi if maxi > maxStockPrice else maxStockPrice\n",
    "    minStockPrice = mini if mini < minStockPrice else minStockPrice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train model on 117 data points.\n"
     ]
    }
   ],
   "source": [
    "def gen_x_and_y(training_dataframes):\n",
    "    x = []  # This is our training list\n",
    "    y = []  # This is our resultant list\n",
    "\n",
    "    for index, stock_dataframe in enumerate(training_dataframes):\n",
    "        # Convert dataframe to np.array\n",
    "        # NOTE: The first element represents the price, while the second represents the sentiment\n",
    "        stock_arr = stock_dataframe.values\n",
    "\n",
    "        # Init lists to store data\n",
    "        stock_prices = []\n",
    "        sentiment_scores = []\n",
    "\n",
    "        for entry in stock_arr:  # Each row is a new entry\n",
    "            # Append the original price to stockPrices\n",
    "            stock_prices.append(entry[0])\n",
    "\n",
    "            # Append the sentiment score to sentimentScores\n",
    "            sentiment_scores.append(entry[1])\n",
    "\n",
    "        # Calculate moving average for stock prices\n",
    "        stock_ma = []\n",
    "        for j in range(len(stock_prices)):\n",
    "            stock_ma.append(sum(stock_prices[j:j + NO_ENTRIES_TAKING_AVG]) / NO_ENTRIES_TAKING_AVG)\n",
    "\n",
    "        # Calculate moving average for sentiments\n",
    "        sentiment_ma = []\n",
    "        for j in range(len(sentiment_scores)):\n",
    "            sentiment_ma.append(sum(sentiment_scores[j:j + NO_ENTRIES_TAKING_AVG]) / NO_ENTRIES_TAKING_AVG)\n",
    "\n",
    "        # Gather future prediction\n",
    "        last_n_unavailable = 0\n",
    "\n",
    "        for j in savedPricesIndexes[index]:\n",
    "            try:\n",
    "                # Calculate normalized values\n",
    "                normalised_stock = (stockValues[index][j + FORECAST_STEP] - minStockPrice) / (maxStockPrice - minStockPrice)\n",
    "                y.append([normalised_stock])  # Must follow the same shape\n",
    "\n",
    "            except IndexError:\n",
    "                last_n_unavailable += 1  # Increment the number of elements which cannot be found\n",
    "\n",
    "        # Gather sentiment and stock value\n",
    "        for j in range(len(sentiment_ma) - last_n_unavailable):\n",
    "            # Calculate normalized values\n",
    "            normalised_stock = (stock_ma[j] - minStockPrice) / (maxStockPrice - minStockPrice)\n",
    "            normalised_sentiment = (sentiment_ma[j] + 1) / 2\n",
    "\n",
    "            x.append([normalised_stock, normalised_sentiment])\n",
    "    \n",
    "    return np.array(x).reshape((np.array(x).shape[0], 1, 2)), np.array(y)\n",
    "\n",
    "X_train, Y_train = gen_x_and_y(trainingDFs)\n",
    "\n",
    "print(\"Will train model on {} data points.\".format(X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Creation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1,2), return_sequences=True))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(LSTM(8, return_sequences=True))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(LSTM(4, return_sequences=True))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(LSTM(2))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Loss Function\n",
    "model.compile(loss=\"mse\", optimizer='adam', metrics=[\"mae\"])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_maker = ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                   filepath=OUTPUT_DIRECTORY + MODEL_CHECKPOINT_NAME + \".hdf5\",\n",
    "                                   verbose=1, save_best_only=True)\n",
    "stop_early = EarlyStopping(monitor=\"val_loss\", patience=80, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1, factor=0.85)  # Reduce learning rate if there is no improvement.\n",
    "\n",
    "# Save model image\n",
    "plot_model(model, OUTPUT_DIRECTORY + MODEL_PLOT_NAME + \".png\", show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 0.2636 - mean_absolute_error: 0.4398 - val_loss: 0.4970 - val_mean_absolute_error: 0.6906\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49698, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 290us/step - loss: 0.2600 - mean_absolute_error: 0.4357 - val_loss: 0.4914 - val_mean_absolute_error: 0.6865\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49698 to 0.49139, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 303us/step - loss: 0.2564 - mean_absolute_error: 0.4317 - val_loss: 0.4858 - val_mean_absolute_error: 0.6824\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.49139 to 0.48582, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 342us/step - loss: 0.2529 - mean_absolute_error: 0.4276 - val_loss: 0.4802 - val_mean_absolute_error: 0.6783\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.48582 to 0.48021, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 328us/step - loss: 0.2495 - mean_absolute_error: 0.4235 - val_loss: 0.4746 - val_mean_absolute_error: 0.6742\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48021 to 0.47460, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 282us/step - loss: 0.2461 - mean_absolute_error: 0.4196 - val_loss: 0.4690 - val_mean_absolute_error: 0.6700\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47460 to 0.46901, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 285us/step - loss: 0.2423 - mean_absolute_error: 0.4155 - val_loss: 0.4634 - val_mean_absolute_error: 0.6658\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46901 to 0.46339, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 275us/step - loss: 0.2392 - mean_absolute_error: 0.4115 - val_loss: 0.4578 - val_mean_absolute_error: 0.6616\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.46339 to 0.45778, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.2357 - mean_absolute_error: 0.4071 - val_loss: 0.4522 - val_mean_absolute_error: 0.6573\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.45778 to 0.45217, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 400us/step - loss: 0.2317 - mean_absolute_error: 0.4027 - val_loss: 0.4465 - val_mean_absolute_error: 0.6530\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45217 to 0.44655, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 334us/step - loss: 0.2287 - mean_absolute_error: 0.3984 - val_loss: 0.4409 - val_mean_absolute_error: 0.6487\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44655 to 0.44090, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 298us/step - loss: 0.2254 - mean_absolute_error: 0.3943 - val_loss: 0.4352 - val_mean_absolute_error: 0.6443\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44090 to 0.43522, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 277us/step - loss: 0.2216 - mean_absolute_error: 0.3904 - val_loss: 0.4295 - val_mean_absolute_error: 0.6398\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43522 to 0.42951, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 429us/step - loss: 0.2185 - mean_absolute_error: 0.3860 - val_loss: 0.4238 - val_mean_absolute_error: 0.6353\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.42951 to 0.42379, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 318us/step - loss: 0.2151 - mean_absolute_error: 0.3818 - val_loss: 0.4180 - val_mean_absolute_error: 0.6307\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.42379 to 0.41802, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 354us/step - loss: 0.2117 - mean_absolute_error: 0.3768 - val_loss: 0.4122 - val_mean_absolute_error: 0.6261\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.41802 to 0.41222, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.2082 - mean_absolute_error: 0.3736 - val_loss: 0.4064 - val_mean_absolute_error: 0.6214\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.41222 to 0.40640, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 370us/step - loss: 0.2050 - mean_absolute_error: 0.3693 - val_loss: 0.4005 - val_mean_absolute_error: 0.6166\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.40640 to 0.40050, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 319us/step - loss: 0.2016 - mean_absolute_error: 0.3656 - val_loss: 0.3945 - val_mean_absolute_error: 0.6117\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.40050 to 0.39454, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 339us/step - loss: 0.1967 - mean_absolute_error: 0.3588 - val_loss: 0.3885 - val_mean_absolute_error: 0.6067\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.39454 to 0.38845, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 370us/step - loss: 0.1934 - mean_absolute_error: 0.3546 - val_loss: 0.3823 - val_mean_absolute_error: 0.6015\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.38845 to 0.38226, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.1891 - mean_absolute_error: 0.3502 - val_loss: 0.3759 - val_mean_absolute_error: 0.5962\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.38226 to 0.37592, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 325us/step - loss: 0.1863 - mean_absolute_error: 0.3464 - val_loss: 0.3694 - val_mean_absolute_error: 0.5906\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.37592 to 0.36942, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.1812 - mean_absolute_error: 0.3388 - val_loss: 0.3628 - val_mean_absolute_error: 0.5849\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.36942 to 0.36281, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 361us/step - loss: 0.1779 - mean_absolute_error: 0.3361 - val_loss: 0.3560 - val_mean_absolute_error: 0.5789\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.36281 to 0.35597, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 333us/step - loss: 0.1766 - mean_absolute_error: 0.3323 - val_loss: 0.3490 - val_mean_absolute_error: 0.5728\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35597 to 0.34901, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 431us/step - loss: 0.1700 - mean_absolute_error: 0.3263 - val_loss: 0.3418 - val_mean_absolute_error: 0.5663\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34901 to 0.34183, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 386us/step - loss: 0.1629 - mean_absolute_error: 0.3184 - val_loss: 0.3344 - val_mean_absolute_error: 0.5595\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34183 to 0.33437, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 373us/step - loss: 0.1612 - mean_absolute_error: 0.3180 - val_loss: 0.3266 - val_mean_absolute_error: 0.5524\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33437 to 0.32662, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 346us/step - loss: 0.1556 - mean_absolute_error: 0.3098 - val_loss: 0.3186 - val_mean_absolute_error: 0.5448\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.32662 to 0.31863, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 359us/step - loss: 0.1535 - mean_absolute_error: 0.3057 - val_loss: 0.3104 - val_mean_absolute_error: 0.5370\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.31863 to 0.31043, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 346us/step - loss: 0.1453 - mean_absolute_error: 0.2970 - val_loss: 0.3020 - val_mean_absolute_error: 0.5287\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.31043 to 0.30199, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 292us/step - loss: 0.1418 - mean_absolute_error: 0.2912 - val_loss: 0.2933 - val_mean_absolute_error: 0.5200\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.30199 to 0.29327, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 0.1366 - mean_absolute_error: 0.2875 - val_loss: 0.2843 - val_mean_absolute_error: 0.5110\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.29327 to 0.28435, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 342us/step - loss: 0.1321 - mean_absolute_error: 0.2814 - val_loss: 0.2753 - val_mean_absolute_error: 0.5015\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.28435 to 0.27526, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 314us/step - loss: 0.1258 - mean_absolute_error: 0.2762 - val_loss: 0.2660 - val_mean_absolute_error: 0.4916\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.27526 to 0.26601, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 340us/step - loss: 0.1235 - mean_absolute_error: 0.2677 - val_loss: 0.2567 - val_mean_absolute_error: 0.4814\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.26601 to 0.25669, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.1128 - mean_absolute_error: 0.2573 - val_loss: 0.2474 - val_mean_absolute_error: 0.4709\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.25669 to 0.24735, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 0s 356us/step - loss: 0.1136 - mean_absolute_error: 0.2608 - val_loss: 0.2381 - val_mean_absolute_error: 0.4602\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.24735 to 0.23811, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 0s 361us/step - loss: 0.1153 - mean_absolute_error: 0.2553 - val_loss: 0.2292 - val_mean_absolute_error: 0.4495\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.23811 to 0.22916, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 0s 330us/step - loss: 0.1066 - mean_absolute_error: 0.2491 - val_loss: 0.2205 - val_mean_absolute_error: 0.4389\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.22916 to 0.22051, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.1025 - mean_absolute_error: 0.2459 - val_loss: 0.2121 - val_mean_absolute_error: 0.4283\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.22051 to 0.21214, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 0s 373us/step - loss: 0.0921 - mean_absolute_error: 0.2363 - val_loss: 0.2040 - val_mean_absolute_error: 0.4177\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.21214 to 0.20403, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 0s 319us/step - loss: 0.0987 - mean_absolute_error: 0.2453 - val_loss: 0.1965 - val_mean_absolute_error: 0.4074\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.20403 to 0.19649, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 0s 284us/step - loss: 0.0923 - mean_absolute_error: 0.2380 - val_loss: 0.1895 - val_mean_absolute_error: 0.3976\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.19649 to 0.18947, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 0s 336us/step - loss: 0.0874 - mean_absolute_error: 0.2325 - val_loss: 0.1829 - val_mean_absolute_error: 0.3882\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.18947 to 0.18291, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 0s 355us/step - loss: 0.0827 - mean_absolute_error: 0.2227 - val_loss: 0.1768 - val_mean_absolute_error: 0.3791\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.18291 to 0.17680, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 0s 318us/step - loss: 0.0841 - mean_absolute_error: 0.2358 - val_loss: 0.1712 - val_mean_absolute_error: 0.3704\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.17680 to 0.17116, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 0s 404us/step - loss: 0.0841 - mean_absolute_error: 0.2424 - val_loss: 0.1662 - val_mean_absolute_error: 0.3625\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.17116 to 0.16619, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 0s 322us/step - loss: 0.0718 - mean_absolute_error: 0.2139 - val_loss: 0.1617 - val_mean_absolute_error: 0.3551\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.16619 to 0.16169, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 0s 311us/step - loss: 0.0798 - mean_absolute_error: 0.2243 - val_loss: 0.1578 - val_mean_absolute_error: 0.3486\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.16169 to 0.15783, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 0s 338us/step - loss: 0.0848 - mean_absolute_error: 0.2363 - val_loss: 0.1545 - val_mean_absolute_error: 0.3427\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15783 to 0.15448, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 0s 329us/step - loss: 0.0846 - mean_absolute_error: 0.2416 - val_loss: 0.1517 - val_mean_absolute_error: 0.3377\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.15448 to 0.15165, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 0s 350us/step - loss: 0.0770 - mean_absolute_error: 0.2204 - val_loss: 0.1493 - val_mean_absolute_error: 0.3333\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.15165 to 0.14927, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 0s 308us/step - loss: 0.0726 - mean_absolute_error: 0.2219 - val_loss: 0.1473 - val_mean_absolute_error: 0.3296\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.14927 to 0.14727, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 0s 455us/step - loss: 0.0831 - mean_absolute_error: 0.2357 - val_loss: 0.1456 - val_mean_absolute_error: 0.3263\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.14727 to 0.14559, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 0s 317us/step - loss: 0.0796 - mean_absolute_error: 0.2297 - val_loss: 0.1442 - val_mean_absolute_error: 0.3236\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.14559 to 0.14425, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 0s 312us/step - loss: 0.0810 - mean_absolute_error: 0.2316 - val_loss: 0.1431 - val_mean_absolute_error: 0.3213\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.14425 to 0.14311, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 0s 320us/step - loss: 0.0823 - mean_absolute_error: 0.2372 - val_loss: 0.1423 - val_mean_absolute_error: 0.3197\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.14311 to 0.14226, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 0s 373us/step - loss: 0.0811 - mean_absolute_error: 0.2317 - val_loss: 0.1417 - val_mean_absolute_error: 0.3186\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.14226 to 0.14174, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 384us/step - loss: 0.0851 - mean_absolute_error: 0.2341 - val_loss: 0.1413 - val_mean_absolute_error: 0.3177\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.14174 to 0.14128, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 0s 395us/step - loss: 0.0737 - mean_absolute_error: 0.2297 - val_loss: 0.1408 - val_mean_absolute_error: 0.3167\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.14128 to 0.14079, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 0s 328us/step - loss: 0.0665 - mean_absolute_error: 0.2089 - val_loss: 0.1404 - val_mean_absolute_error: 0.3159\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.14079 to 0.14044, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 0s 347us/step - loss: 0.0725 - mean_absolute_error: 0.2201 - val_loss: 0.1401 - val_mean_absolute_error: 0.3151\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.14044 to 0.14006, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 0s 365us/step - loss: 0.0784 - mean_absolute_error: 0.2382 - val_loss: 0.1399 - val_mean_absolute_error: 0.3146\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.14006 to 0.13988, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 0s 296us/step - loss: 0.0802 - mean_absolute_error: 0.2364 - val_loss: 0.1397 - val_mean_absolute_error: 0.3142\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.13988 to 0.13975, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 0s 323us/step - loss: 0.0731 - mean_absolute_error: 0.2273 - val_loss: 0.1397 - val_mean_absolute_error: 0.3140\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.13975 to 0.13972, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 0s 346us/step - loss: 0.0727 - mean_absolute_error: 0.2233 - val_loss: 0.1396 - val_mean_absolute_error: 0.3137\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.13972 to 0.13963, saving model to ./output/ForecasterCP_FC5.hdf5\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 0s 353us/step - loss: 0.0844 - mean_absolute_error: 0.2329 - val_loss: 0.1396 - val_mean_absolute_error: 0.3135\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.13963\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 0s 317us/step - loss: 0.0763 - mean_absolute_error: 0.2283 - val_loss: 0.1397 - val_mean_absolute_error: 0.3135\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.13963\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 0s 388us/step - loss: 0.0713 - mean_absolute_error: 0.2242 - val_loss: 0.1399 - val_mean_absolute_error: 0.3137\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.13963\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 0s 452us/step - loss: 0.0816 - mean_absolute_error: 0.2309 - val_loss: 0.1403 - val_mean_absolute_error: 0.3143\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.13963\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 0s 409us/step - loss: 0.0752 - mean_absolute_error: 0.2230 - val_loss: 0.1407 - val_mean_absolute_error: 0.3149\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.13963\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0008500000403728336.\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 0s 358us/step - loss: 0.0738 - mean_absolute_error: 0.2144 - val_loss: 0.1410 - val_mean_absolute_error: 0.3153\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.13963\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 0s 377us/step - loss: 0.0670 - mean_absolute_error: 0.2203 - val_loss: 0.1414 - val_mean_absolute_error: 0.3158\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.13963\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 0s 367us/step - loss: 0.0691 - mean_absolute_error: 0.2190 - val_loss: 0.1417 - val_mean_absolute_error: 0.3163\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.13963\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 0s 350us/step - loss: 0.0746 - mean_absolute_error: 0.2262 - val_loss: 0.1420 - val_mean_absolute_error: 0.3167\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.13963\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 0s 373us/step - loss: 0.0678 - mean_absolute_error: 0.2136 - val_loss: 0.1422 - val_mean_absolute_error: 0.3168\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.13963\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0007225000590551645.\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 0s 434us/step - loss: 0.0730 - mean_absolute_error: 0.2251 - val_loss: 0.1422 - val_mean_absolute_error: 0.3167\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.13963\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 0s 431us/step - loss: 0.0700 - mean_absolute_error: 0.2136 - val_loss: 0.1422 - val_mean_absolute_error: 0.3166\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.13963\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 0s 350us/step - loss: 0.0702 - mean_absolute_error: 0.2194 - val_loss: 0.1421 - val_mean_absolute_error: 0.3163\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.13963\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 0s 367us/step - loss: 0.0759 - mean_absolute_error: 0.2251 - val_loss: 0.1421 - val_mean_absolute_error: 0.3162\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.13963\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 0s 335us/step - loss: 0.0767 - mean_absolute_error: 0.2265 - val_loss: 0.1422 - val_mean_absolute_error: 0.3162\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.13963\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0006141250254586339.\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 0s 295us/step - loss: 0.0729 - mean_absolute_error: 0.2236 - val_loss: 0.1422 - val_mean_absolute_error: 0.3162\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.13963\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 0s 350us/step - loss: 0.0645 - mean_absolute_error: 0.2113 - val_loss: 0.1422 - val_mean_absolute_error: 0.3161\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.13963\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 0s 367us/step - loss: 0.0604 - mean_absolute_error: 0.2039 - val_loss: 0.1422 - val_mean_absolute_error: 0.3159\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.13963\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 0s 408us/step - loss: 0.0642 - mean_absolute_error: 0.2110 - val_loss: 0.1421 - val_mean_absolute_error: 0.3156\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.13963\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 0s 411us/step - loss: 0.0734 - mean_absolute_error: 0.2293 - val_loss: 0.1420 - val_mean_absolute_error: 0.3153\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.13963\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0005220062914304435.\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 0s 441us/step - loss: 0.0713 - mean_absolute_error: 0.2197 - val_loss: 0.1420 - val_mean_absolute_error: 0.3152\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.13963\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 0s 390us/step - loss: 0.0858 - mean_absolute_error: 0.2312 - val_loss: 0.1420 - val_mean_absolute_error: 0.3153\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.13963\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 0s 397us/step - loss: 0.0703 - mean_absolute_error: 0.2194 - val_loss: 0.1422 - val_mean_absolute_error: 0.3154\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.13963\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 0s 389us/step - loss: 0.0851 - mean_absolute_error: 0.2367 - val_loss: 0.1422 - val_mean_absolute_error: 0.3155\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.13963\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 0s 346us/step - loss: 0.0782 - mean_absolute_error: 0.2305 - val_loss: 0.1423 - val_mean_absolute_error: 0.3155\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.13963\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00044370535761117935.\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 0s 357us/step - loss: 0.0803 - mean_absolute_error: 0.2320 - val_loss: 0.1423 - val_mean_absolute_error: 0.3155\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.13963\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 372us/step - loss: 0.0829 - mean_absolute_error: 0.2337 - val_loss: 0.1424 - val_mean_absolute_error: 0.3156\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.13963\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 0s 413us/step - loss: 0.0698 - mean_absolute_error: 0.2177 - val_loss: 0.1424 - val_mean_absolute_error: 0.3156\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.13963\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 0s 449us/step - loss: 0.0718 - mean_absolute_error: 0.2218 - val_loss: 0.1425 - val_mean_absolute_error: 0.3157\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.13963\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 0s 382us/step - loss: 0.0749 - mean_absolute_error: 0.2277 - val_loss: 0.1426 - val_mean_absolute_error: 0.3158\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.13963\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.00037714955396950245.\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 0s 399us/step - loss: 0.0738 - mean_absolute_error: 0.2328 - val_loss: 0.1427 - val_mean_absolute_error: 0.3159\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.13963\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 0s 369us/step - loss: 0.0646 - mean_absolute_error: 0.2098 - val_loss: 0.1427 - val_mean_absolute_error: 0.3160\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.13963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e8a2eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=NO_EPOCHS, verbose=1, validation_split=VAL_SPLIT, callbacks=[checkpoint_maker, stop_early, reduce_lr], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(OUTPUT_DIRECTORY + MODEL_OUTPUT_NAME + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting testing stock and sentiment files: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get all testing data\n",
    "testingDirs = next(os.walk(TESTING_DIRECTORY))[1]  # All the subdirectories\n",
    "\n",
    "testingDFs = []\n",
    "stockValues = []\n",
    "savedPricesIndexes = []\n",
    "\n",
    "maxStockPrice = -float(\"inf\")\n",
    "minStockPrice = float(\"inf\")\n",
    "\n",
    "for directory in tqdm(testingDirs, desc=\"Getting testing stock and sentiment files\"):\n",
    "    combinedDataframe, tempStockValues, tempSavedPricesIndexes, maxi, mini = get_data_values(directory, TESTING_DIRECTORY)\n",
    "    \n",
    "    testingDFs.append(combinedDataframe)\n",
    "    stockValues.append(tempStockValues)\n",
    "    savedPricesIndexes.append(tempSavedPricesIndexes)\n",
    "\n",
    "    maxStockPrice = maxi if maxi > maxStockPrice else maxStockPrice\n",
    "    minStockPrice = mini if mini < minStockPrice else minStockPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will test model on 263 data points.\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = gen_x_and_y(testingDFs)\n",
    "print(\"Will test model on {} data points.\".format(X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 1, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0249521341 0.3723124564 1392.1066679270%\n",
      "0.0277246104 0.3740393221 1249.1238164377%\n",
      "0.0232312831 0.3769199252 1522.4671021545%\n",
      "0.0230401167 0.3780537844 1540.8501276625%\n",
      "0.0553536663 0.3788244426 584.3710050972%\n",
      "0.0387188848 0.3802673221 882.1236437435%\n",
      "0.0434033785 0.3817211688 779.4734004312%\n",
      "0.0429254148 0.3849523664 796.7935855619%\n",
      "0.0372848407 0.3883454800 941.5640052075%\n",
      "0.0476098989 0.3908050358 720.8482785731%\n",
      "0.0558317065 0.3940671384 605.8124548978%\n",
      "0.1061185369 0.3965035081 273.6420797354%\n",
      "0.0998087466 0.4010450244 301.8135062368%\n",
      "0.0900573500 0.4030264914 347.5220416562%\n",
      "0.1180688247 0.4036943018 241.9143901043%\n",
      "0.2062141573 0.4048881531 96.3435286565%\n",
      "0.2411089404 0.4085056186 69.4278187393%\n",
      "0.3505736248 0.4106309414 17.1311565761%\n",
      "0.3485659095 0.4124384820 18.3243888077%\n",
      "0.3925430261 0.4149697423 5.7131867537%\n",
      "0.4263861839 0.4167949855 2.2494158450%\n",
      "0.4237093290 0.4195920527 0.9717218904%\n",
      "0.4186424165 0.4202520251 0.3844829253%\n",
      "0.4836520110 0.4232425988 12.4902638411%\n",
      "0.5290631048 0.4264651835 19.3923787860%\n",
      "0.5328871395 0.4298499823 19.3356434475%\n",
      "0.5654875630 0.4320296049 23.6005116323%\n",
      "0.5384320922 0.4345725775 19.2892504443%\n",
      "0.5114723193 0.4366677403 14.6253425980%\n",
      "0.5372849124 0.4374844730 18.5749566190%\n",
      "0.5673040259 0.4386675656 22.6750480197%\n",
      "0.5840344288 0.4391204417 24.8125761096%\n",
      "0.7398662109 0.4401291907 40.5123272009%\n",
      "0.7322179980 0.4409978390 39.7723300734%\n",
      "0.6963671345 0.4416019320 36.5848975089%\n",
      "0.7010516951 0.4422928393 36.9100963070%\n",
      "0.7806884324 0.4433293641 43.2130225481%\n",
      "0.7604206486 0.4430757463 41.7328097136%\n",
      "0.7622371115 0.4432159364 41.8532724593%\n",
      "0.7662523986 0.4441777170 42.0324533056%\n",
      "0.7676865192 0.4450455010 42.0277040357%\n",
      "0.7694072842 0.4470355213 41.8987147037%\n",
      "0.7758126289 0.4484648705 42.1941775951%\n",
      "0.7352773386 0.4492229819 38.9042802835%\n",
      "0.7762906691 0.4498269856 42.0543098726%\n",
      "0.7602294058 0.4489567876 40.9445643398%\n",
      "0.8290631784 0.4477417469 45.9942548936%\n",
      "0.8413002636 0.4483259022 46.7103575708%\n",
      "0.8565009915 0.4486452043 47.6188342139%\n",
      "0.8842256019 0.4470615685 49.4403274977%\n",
      "0.8439771089 0.4476718307 46.9568752625%\n",
      "0.7791587668 0.4481370747 42.4844981824%\n",
      "0.7521032961 0.4473463893 40.5206184269%\n",
      "0.7271510855 0.4465521574 38.5888068793%\n",
      "0.7572657535 0.4464873374 41.0395445336%\n",
      "0.7462715460 0.4476267695 40.0182451128%\n",
      "0.7011472496 0.4503014982 35.7764722862%\n",
      "0.7445506281 0.4507800043 39.4560977803%\n",
      "0.7066922023 0.4498085976 36.3501399757%\n",
      "0.8636711642 0.4507555366 47.8093567029%\n",
      "0.8544932762 0.4496735930 47.3754088453%\n",
      "0.8166348504 0.4484518170 45.0853932052%\n",
      "0.8220841052 0.4501444101 45.2435088681%\n",
      "0.8184513133 0.4505153894 44.9551387910%\n",
      "0.8968451728 0.4500774145 49.8154834102%\n",
      "0.7850860618 0.4500595927 42.6738526368%\n",
      "0.8294455207 0.4493798316 45.8216579222%\n",
      "0.7728489766 0.4484582245 41.9733689123%\n",
      "0.8512428361 0.4480417967 47.3661594955%\n",
      "0.7953155751 0.4479301870 43.6789368902%\n",
      "0.8504779986 0.4478021562 47.3470028686%\n",
      "0.8665392619 0.4464861453 48.4747933684%\n",
      "0.8486615357 0.4437791705 47.7083440422%\n",
      "0.9018165307 0.4430394769 50.8725487097%\n",
      "0.8804015671 0.4433833659 49.6385078793%\n",
      "0.7980879750 0.4417119026 44.6537328632%\n",
      "0.6831739689 0.4390588105 35.7325029276%\n",
      "0.7522945389 0.4388496876 41.6651770185%\n",
      "0.7356596904 0.4402575195 40.1547311618%\n",
      "0.7293499002 0.4427571297 39.2942770639%\n",
      "0.7675908213 0.4451664984 42.0047131795%\n",
      "0.7933078598 0.4475159645 43.5886133038%\n",
      "0.7376673962 0.4489805400 39.1350976917%\n",
      "0.7139579199 0.4517665207 36.7236488143%\n",
      "0.7660611462 0.4525433183 40.9259534301%\n",
      "0.7938814545 0.4534676969 42.8796712265%\n",
      "0.9359464859 0.4556748867 51.3140020743%\n",
      "0.9173040655 0.4559013546 50.2998654779%\n",
      "0.9582218320 0.4551080167 52.5049418052%\n",
      "1.0512428342 0.4529449642 56.9133839091%\n",
      "1.0505736946 0.4508527219 57.0850931975%\n",
      "0.8509560388 0.4494725168 47.1802894297%\n",
      "0.9010517028 0.4485956430 50.2142172679%\n",
      "0.9519120513 0.4456905425 53.1794411211%\n",
      "0.8260995261 0.4442011416 46.2291010300%\n",
      "0.8491395759 0.4437372684 47.7427173310%\n",
      "0.7531549214 0.4418516457 41.3332326254%\n",
      "0.7801147038 0.4405173361 43.5317224550%\n",
      "0.7086042197 0.4386408627 38.0979042281%\n",
      "0.6827916266 0.4370718002 35.9875277921%\n",
      "0.7057361219 0.4353696406 38.3098544805%\n",
      "0.7248565824 0.4347234070 40.0262869154%\n",
      "0.7627151517 0.4336921871 43.1383805445%\n",
      "0.7656788039 0.4316935837 43.6194940344%\n",
      "0.7283939632 0.4297864437 40.9953314557%\n",
      "0.7323135525 0.4271382689 41.6727619620%\n",
      "0.6341300832 0.4246182740 33.0392477515%\n",
      "0.5782026788 0.4238759279 26.6907706489%\n",
      "0.5567877152 0.4250597656 23.6585589148%\n",
      "0.6139579974 0.4243170321 30.8882637067%\n",
      "0.6404397301 0.4238216579 33.8233344989%\n",
      "0.6492352662 0.4232728481 34.8043967766%\n",
      "0.3343212620 0.4207183719 25.8425411853%\n",
      "0.3625239126 0.4228805006 16.6489949502%\n",
      "0.4887189235 0.4249100685 13.0563503730%\n",
      "0.5532504778 0.4266775548 22.8780503666%\n",
      "0.5729445235 0.4292476475 25.0804170510%\n",
      "0.4054493944 0.4304737449 6.1720034282%\n",
      "0.5603250960 0.4319157004 22.9169452682%\n",
      "0.6540153813 0.4361965954 33.3048414627%\n",
      "0.6699809467 0.4396322668 34.3813777252%\n",
      "0.7019120872 0.4407345355 37.2094392565%\n",
      "0.6989484349 0.4449372590 36.3419049615%\n",
      "0.6553538136 0.4472855031 31.7490042943%\n",
      "0.6689293214 0.4479243457 33.0386138879%\n",
      "0.7002868671 0.4492169619 35.8524366312%\n",
      "0.8110898977 0.4507603943 44.4253472259%\n",
      "0.7839388820 0.4522941113 42.3049268704%\n",
      "0.7860421422 0.4387459457 44.1828978199%\n",
      "0.7834608418 0.4216405749 46.1823038955%\n",
      "0.8391969938 0.4026654661 52.0177659073%\n",
      "0.8463671665 0.3826273978 54.7917956988%\n",
      "0.8314532360 0.3596380949 56.7458421784%\n",
      "0.8342256358 0.3331882358 60.0601777926%\n",
      "0.8793499323 0.3091802597 64.8399063487%\n",
      "0.8587954945 0.2862024903 66.6739646227%\n",
      "0.7117591148 0.4408545196 38.0612751629%\n",
      "0.8764818345 0.4398024380 49.8218421979%\n",
      "0.8606118236 0.4382375777 49.0783689378%\n",
      "0.8837477051 0.4359529614 50.6699752737%\n",
      "0.7784894742 0.4346139133 44.1721529097%\n",
      "0.6066921268 0.4312130213 28.9239134232%\n",
      "0.6232314303 0.4288647473 31.1869192667%\n",
      "0.6027725471 0.4279841185 28.9974102948%\n",
      "0.6086042875 0.4265678823 29.9104703947%\n",
      "0.6285851401 0.4254270792 32.3198955809%\n",
      "0.6056405014 0.4260751009 29.6488428557%\n",
      "0.6065965818 0.4241092205 30.0838097001%\n",
      "0.5990440573 0.4231640399 29.3601138834%\n",
      "0.5486616055 0.4226699173 22.9634599745%\n",
      "0.5447418729 0.4234884083 22.2588845443%\n",
      "0.5493307452 0.4253848493 22.5630727834%\n",
      "0.5080306269 0.4275597632 15.8397662334%\n",
      "0.5456022649 0.4298521280 21.2151129736%\n",
      "0.5597515109 0.4313222766 22.9439727789%\n",
      "0.6260038302 0.4323970377 30.9274133932%\n",
      "0.6237093271 0.4324642718 30.6625293223%\n",
      "0.5678776206 0.4326340258 23.8156232705%\n",
      "0.5341300173 0.4346832931 18.6184488713%\n",
      "0.6330784579 0.4369218349 30.9845676338%\n",
      "0.6143403397 0.4382909536 28.6566540829%\n",
      "0.6065010273 0.4385417402 27.6931578977%\n",
      "0.6111854446 0.4395460784 28.0830258054%\n",
      "0.6161568121 0.4386372864 28.8107706005%\n",
      "0.6115679398 0.4383209050 28.3283382863%\n",
      "0.6295410771 0.4385918677 30.3314932685%\n",
      "0.6400573878 0.4367087185 31.7703807683%\n",
      "0.7218929302 0.4378980994 39.3402981087%\n",
      "0.7264818025 0.4355913401 40.0409840158%\n",
      "0.7223709704 0.4345401824 39.8452872316%\n",
      "0.6938815224 0.4336725473 37.5004905983%\n",
      "0.7231358079 0.4328728616 40.1394790738%\n",
      "0.7136711322 0.4295976162 39.8045406572%\n",
      "0.6627150857 0.4280554354 35.4088288234%\n",
      "0.6712236811 0.4262991548 36.4892558510%\n",
      "0.6317400257 0.4238972366 32.9000507555%\n",
      "0.6366156953 0.4246586561 33.2943470844%\n",
      "0.6939770769 0.4231068492 39.0315814073%\n",
      "0.5892925842 0.4219528735 28.3967107670%\n",
      "0.5992351567 0.4206122756 29.8084782106%\n",
      "0.5416826757 0.4165603817 23.0988177469%\n",
      "0.4037284764 0.4128548205 2.2605153222%\n",
      "0.4326004196 0.4125880003 4.6260748777%\n",
      "0.3771510554 0.4112178981 9.0326786171%\n",
      "0.4055449489 0.4090129435 0.8551443346%\n",
      "0.4131931617 0.4082326591 1.2005287369%\n",
      "0.3965583037 0.4066269398 2.5390052257%\n",
      "0.3908221082 0.4076124430 4.2961578737%\n",
      "0.3778201950 0.4095126987 8.3882502933%\n",
      "0.2342256416 0.4107207656 75.3526056502%\n",
      "0.2521988458 0.4127013981 63.6412715685%\n",
      "0.3450286721 0.4168750942 20.8233192901%\n",
      "0.3437857944 0.4189420044 21.8613483362%\n",
      "0.3990439158 0.4215668440 5.6442229308%\n",
      "0.3994264015 0.4243465364 6.2389804042%\n",
      "0.4492351247 0.4271238446 4.9219838023%\n",
      "0.4844168486 0.4292491972 11.3884666651%\n",
      "0.4977055591 0.4296149313 13.6809056056%\n",
      "0.5033460663 0.4293915033 14.6925878392%\n",
      "0.5847992664 0.4294019341 26.5727645648%\n",
      "0.6018164667 0.4285919368 28.7836141839%\n",
      "0.6018164667 0.4277804792 28.9184489182%\n",
      "0.5792543137 0.4276783466 26.1674300015%\n",
      "0.4896750039 0.4289015830 12.4109706341%\n",
      "0.5016252917 0.4300888479 14.2609324193%\n",
      "0.5105162390 0.4302629530 15.7200260810%\n",
      "0.5198852168 0.4316883683 16.9646771331%\n",
      "0.5158699392 0.4336535037 15.9374348680%\n",
      "0.5164435339 0.4354364872 15.6855573555%\n",
      "0.6143403397 0.4365045726 28.9474344356%\n",
      "0.6100382647 0.4393838346 27.9743812795%\n",
      "0.5870937694 0.4416582286 24.7721145033%\n",
      "0.5890057868 0.4433229268 24.7336890940%\n",
      "0.6588910510 0.4418417513 32.9416068566%\n",
      "0.6563097505 0.4404786527 32.8855540617%\n",
      "0.7542065563 0.4402109981 41.6325681092%\n",
      "0.7812620271 0.4382165372 43.9091467326%\n",
      "0.7960802693 0.4362714887 45.1975503587%\n",
      "0.7936902117 0.4341553450 45.2991433476%\n",
      "0.7864244845 0.4326436520 44.9859890563%\n",
      "0.7204589530 0.4310235381 40.1737550327%\n",
      "0.7275334374 0.4275352657 41.2349668442%\n",
      "0.5893881387 0.4227871299 28.2667732616%\n",
      "0.5918738846 0.4231201410 28.5117738670%\n",
      "0.5802103941 0.4248861372 26.7703333869%\n",
      "0.4967494787 0.4236584604 14.7138590869%\n",
      "0.5126194992 0.4235929847 17.3669777761%\n",
      "0.5427341672 0.4235053360 21.9681822752%\n",
      "0.5352771971 0.4247809350 20.6428113613%\n",
      "0.4460803730 0.4256693125 4.5756463966%\n",
      "0.4276290521 0.4269530475 0.1580820043%\n",
      "0.4682600307 0.4276862442 8.6647981501%\n",
      "0.5266730472 0.4310037792 18.1648308298%\n",
      "0.5276291276 0.4315972030 18.2006488220%\n",
      "0.5082218697 0.4302138090 15.3492136732%\n",
      "0.4833652137 0.4296607077 11.1105442515%\n",
      "0.5075525867 0.4291016757 15.4567059651%\n",
      "0.5171128170 0.4275626540 17.3173357930%\n",
      "0.6760037962 0.4260163307 36.9801866344%\n",
      "0.6114722419 0.4231337011 30.8008324682%\n",
      "0.6485659831 0.4215786457 34.9983414700%\n",
      "0.6589865959 0.4200323820 36.2608610515%\n",
      "0.5459847506 0.4183371961 23.3793259530%\n",
      "0.4917782641 0.4162742794 15.3532578125%\n",
      "0.5326003422 0.4177121818 21.5711766000%\n",
      "0.4618546956 0.4163962901 9.8425773177%\n",
      "0.3735181201 0.4163613617 11.4701909613%\n",
      "0.4112810010 0.4126131237 0.3238959936%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4586042555 0.4094347656 10.7215511743%\n",
      "0.4617591506 0.4069552422 11.8685051282%\n",
      "0.5086042216 0.4026439190 20.8335475984%\n",
      "0.5075525867 0.4011756480 20.9588014143%\n",
      "0.3882409512 0.4000574648 3.0436031065%\n",
      "0.4057361917 0.3998885751 1.4412361383%\n",
      "0.2753345839 0.3974028826 44.3345317970%\n",
      "0.2680687898 0.3977864683 48.3896982453%\n",
      "0.2069789279 0.3965130448 91.5716970685%\n",
      "0.2362332804 0.3850357234 62.9896189284%\n",
      "0.2526768095 0.3708152175 46.7547489709%\n",
      "0.1458890565 0.3560692370 144.0685034668%\n",
      "0.2218929350 0.3413960040 53.8561847496%\n",
      "0.3997131988 0.3246702850 18.7741896094%\n",
      "0.3845124709 0.3066940904 20.2381941958%\n",
      "\n",
      "Mean Percentage Error: 77.4081815675%\n",
      "Highest Percentage Error: 1540.8501276625%\n",
      "Lowest Percentage Error: 0.1580820043%\n",
      "Standard deviation: 1463.44%\n"
     ]
    }
   ],
   "source": [
    "totalError = 0\n",
    "highestPercentageError = -float(\"inf\")\n",
    "lowestPercentageError = float(\"inf\")\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    Y_pred = model.predict(np.array([X_test[i]]))\n",
    "    percentageError = (abs(Y_pred[0][0] - Y_test[i][0]) / Y_test[i][0]) * 100\n",
    "    \n",
    "    print(f\"{Y_test[i][0]:.10f} {Y_pred[0][0]:.10f} {percentageError:.10f}%\")\n",
    "    \n",
    "    highestPercentageError = percentageError if highestPercentageError < percentageError else highestPercentageError\n",
    "    lowestPercentageError = percentageError if lowestPercentageError > percentageError else lowestPercentageError\n",
    "    \n",
    "    totalError += percentageError\n",
    "\n",
    "print()\n",
    "print(f\"Mean Percentage Error: {totalError / X_test.shape[0]:.10f}%\")\n",
    "print(f\"Highest Percentage Error: {highestPercentageError:.10f}%\")\n",
    "print(f\"Lowest Percentage Error: {lowestPercentageError:.10f}%\")\n",
    "print(f\"Standard deviation: {max(abs(lowestPercentageError - totalError / X_test.shape[0]), abs(highestPercentageError - totalError / X_test.shape[0])):5g}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
